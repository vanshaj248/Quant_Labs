{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f93a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "files_path=\"/Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA\"\n",
    "symbol =\"/Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/India50_stocks.parquet\"\n",
    "\n",
    "\n",
    "ds = pd.read_parquet(symbol)[\"Symbol\"]\n",
    "\n",
    "for i in ds:\n",
    "     df = pd.read_parquet(f\"{files_path}/{i}_history.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/COALINDIA_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ICICIBANK_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/HEROMOTOCO_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/WIPRO_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/POWERGRID_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BRITANNIA_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/AXISBANK_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ULTRACEMCO_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/NESTLEIND_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/GRASIM_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BAJAJAUTO_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/SBILIFE_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/JSWSTEEL_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/TATAMOTORS_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/LTIM_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/KOTAKBANK_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/NTPC_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ONGC_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ASIANPAINT_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/DMART_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/SUNPHARMA_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/HINDUNILVR_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/SBIN_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BPCL_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/INFY_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/TATASTEEL_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/HDFCLIFE_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BAJAJFINSV_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/DIVISLAB_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/TECHM_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/IOC_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BHARTIARTL_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ADANIENT_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/TITAN_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/LT_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ITC_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ADANIPORTS_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ADANIPOWER_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/ADANIGREEN_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/HDFCBANK_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/HCLTECH_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/LICI_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/JIOFIN_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/BAJFINANCE_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/PIDILITIND_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/MARUTI_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/RELIANCE_history.parquet\n",
      "Processing: /Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA/TCS_history.parquet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def process_parquet_files(data_folder):\n",
    "    # Get all parquet files in the folder\n",
    "    parquet_files = list(Path(data_folder).glob(\"*.parquet\"))\n",
    "    \n",
    "    # List to store individual DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    # Process each parquet file\n",
    "    for file_path in parquet_files:\n",
    "        print(f\"Processing: {file_path}\")\n",
    "        \n",
    "        # Read parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Apply your preprocessing here\n",
    "        df_processed = preprocess_data(df)\n",
    "        \n",
    "        # Save processed data back to the same file (overwrite)\n",
    "        df_processed.to_parquet(file_path, index=False)\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "     \"\"\"Your preprocessing steps here\"\"\"\n",
    "    \n",
    "     # 1. Handle missing values\n",
    "     df['Date']=pd.to_datetime(df['Date'])\n",
    "     df = df.set_index('Date').sort_index()\n",
    "     start_date = df.index.min()  # or specify: pd.Timestamp('2023-01-01')\n",
    "     end_date = df.index.max()    # or specify: pd.Timestamp('2023-12-31')\n",
    "     complete_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "     missing_dates = complete_date_range.difference(df.index)\n",
    "     if len(missing_dates) > 0:\n",
    "          print(\"Missing dates:\", missing_dates.tolist())\n",
    "            \n",
    "          # Reindex to include missing dates and forward fill\n",
    "          df = df.reindex(complete_date_range)\n",
    "          df = df.ffill()  # Forward fill missing values\n",
    "            \n",
    "            # Reset index to get date column back\n",
    "          df = df.reset_index()\n",
    "          df = df.rename(columns={'index': 'Date'}) \n",
    "     if 'Close' in df.columns:\n",
    "          # Sort by date to ensure correct calculation\n",
    "          df = df.sort_values('Date')\n",
    "          ohlc_columns = ['open', 'high', 'low', 'close']\n",
    "    \n",
    "     for col in ohlc_columns:\n",
    "          if col in df.columns:\n",
    "               # Basic returns\n",
    "               df[f'{col}_return'] = df[col].pct_change()\n",
    "               df[f'{col}_log_return'] = np.log(df[col] / df[col].shift(1))\n",
    "               df[f'{col}_return_pct'] = df[f'{col}_return'] * 100\n",
    "               \n",
    "               # Rolling statistics for each price series\n",
    "               df[f'{col}_return_rolling_7d'] = df[f'{col}_return'].rolling(window=7).mean()\n",
    "               df[f'{col}_return_volatility_30d'] = df[f'{col}_return'].rolling(window=30).std()\n",
    "    \n",
    "     # Special calculations for close price (most important)\n",
    "     if 'close' in df.columns:\n",
    "          df['daily_return'] = df['close'].pct_change()  # Primary returns column\n",
    "          df['log_daily_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "          df['daily_return_pct'] = df['daily_return'] * 100\n",
    "          \n",
    "          # Cumulative returns based on close price\n",
    "          df['cumulative_return'] = (1 + df['daily_return']).cumprod() - 1\n",
    "          df['log_cumulative_return'] = df['log_daily_return'].cumsum()\n",
    "     # Volume analysis\n",
    "     if 'volume' in df.columns:\n",
    "          df['volume_pct_change'] = df['volume'].pct_change()\n",
    "          df['volume_log_change'] = np.log(df['volume'] / df['volume'].shift(1))\n",
    "          \n",
    "          # Volume rolling averages\n",
    "          df['volume_ma_7'] = df['volume'].rolling(window=7).mean()\n",
    "          df['volume_ma_30'] = df['volume'].rolling(window=30).mean()\n",
    "     \n",
    "     # Additional OHLC-based metrics\n",
    "     if all(col in df.columns for col in ['high', 'low']):\n",
    "          df['daily_range'] = df['high'] - df['low']\n",
    "          df['daily_range_pct'] = (df['daily_range'] / df['close'].shift(1)) * 100\n",
    "     \n",
    "     if all(col in df.columns for col in ['open', 'close']):\n",
    "          df['overnight_gap'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "          df['intraday_move'] = (df['close'] - df['open']) / df['open']     \n",
    "    \n",
    "     return df\n",
    "\n",
    "# Usage\n",
    "data_folder = \"/Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA\"\n",
    "combined_data = process_parquet_files(data_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

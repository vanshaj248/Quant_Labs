{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def process_parquet_files(data_folder):\n",
    "    # Get all parquet files in the folder\n",
    "    parquet_files = list(Path(data_folder).glob(\"*.parquet\"))\n",
    "    \n",
    "    # List to store individual DataFrames\n",
    "    dataframes = []\n",
    "    for file_path in parquet_files:\n",
    "          print(f\"Processing: {file_path}\")\n",
    "          # Read parquet file\n",
    "          df = pd.read_parquet(file_path)\n",
    "          # Apply your preprocessing here\n",
    "          df_processed = preprocess_data(df)\n",
    "          # Save processed data back to the same file (overwrite)\n",
    "          df_processed.to_parquet(file_path, index=False)\n",
    "def preprocess_data(df):\n",
    "     \"\"\"Your preprocessing steps here\"\"\"\n",
    "    \n",
    "     # 1. Handle missing values\n",
    "     df['Date']=pd.to_datetime(df['Date'])\n",
    "     df = df.set_index('Date').sort_index()\n",
    "     start_date = df.index.min()  # or specify: pd.Timestamp('2023-01-01')\n",
    "     end_date = df.index.max()    # or specify: pd.Timestamp('2023-12-31')\n",
    "     complete_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "     missing_dates = complete_date_range.difference(df.index)\n",
    "     if len(missing_dates) > 0:\n",
    "          print(\"Missing dates:\", missing_dates.tolist())\n",
    "            \n",
    "          # Reindex to include missing dates and forward fill\n",
    "          df = df.reindex(complete_date_range)\n",
    "          df = df.ffill()  # Forward fill missing values\n",
    "            \n",
    "            # Reset index to get date column back\n",
    "          df = df.reset_index()\n",
    "          df = df.rename(columns={'index': 'Date'}) \n",
    "     if 'Close' in df.columns:\n",
    "          # Sort by date to ensure correct calculation\n",
    "          df = df.sort_values('Date')\n",
    "          ohlc_columns = ['open', 'high', 'low', 'close']\n",
    "    \n",
    "     for col in ohlc_columns:\n",
    "          if col in df.columns:\n",
    "               # Basic returns\n",
    "               df[f'{col}_return'] = df[col].pct_change()\n",
    "               df[f'{col}_log_return'] = np.log(df[col] / df[col].shift(1))\n",
    "               df[f'{col}_return_pct'] = df[f'{col}_return'] * 100\n",
    "               \n",
    "               # Rolling statistics for each price series\n",
    "               df[f'{col}_return_rolling_7d'] = df[f'{col}_return'].rolling(window=7).mean()\n",
    "               df[f'{col}_return_volatility_30d'] = df[f'{col}_return'].rolling(window=30).std()\n",
    "    \n",
    "     # Special calculations for close price (most important)\n",
    "     if 'close' in df.columns:\n",
    "          df['daily_return'] = df['close'].pct_change()  # Primary returns column\n",
    "          df['log_daily_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "          df['daily_return_pct'] = df['daily_return'] * 100\n",
    "          \n",
    "          # Cumulative returns based on close price\n",
    "          df['cumulative_return'] = (1 + df['daily_return']).cumprod() - 1\n",
    "          df['log_cumulative_return'] = df['log_daily_return'].cumsum()\n",
    "     # Volume analysis\n",
    "     if 'volume' in df.columns:\n",
    "          df['volume_pct_change'] = df['volume'].pct_change()\n",
    "          df['volume_log_change'] = np.log(df['volume'] / df['volume'].shift(1))\n",
    "          \n",
    "          # Volume rolling averages\n",
    "          df['volume_ma_7'] = df['volume'].rolling(window=7).mean()\n",
    "          df['volume_ma_30'] = df['volume'].rolling(window=30).mean()\n",
    "     \n",
    "     # Additional OHLC-based metrics\n",
    "     if all(col in df.columns for col in ['high', 'low']):\n",
    "          df['daily_range'] = df['high'] - df['low']\n",
    "          df['daily_range_pct'] = (df['daily_range'] / df['close'].shift(1)) * 100\n",
    "     \n",
    "     if all(col in df.columns for col in ['open', 'close']):\n",
    "          df['overnight_gap'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)\n",
    "          df['intraday_move'] = (df['close'] - df['open']) / df['open']     \n",
    "    \n",
    "     return df\n",
    "\n",
    "# Usage\n",
    "data_folder = \"/Users/vanshaj/Work/GitHub/Quant_Labs/Application/Data/Assets Data/EQUITY/INDIA\"\n",
    "combined_data = process_parquet_files(data_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

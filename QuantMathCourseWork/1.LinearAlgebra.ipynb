{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422d4237",
   "metadata": {},
   "source": [
    "Day 1: Vectors, Vector Spaces, and Inner Product Spaces\n",
    "Let me start with the core concepts and then give you today's practical problems.\n",
    "Key Concepts:\n",
    "* Vectors: Objects that have magnitude and direction, represented as arrays of numbers\n",
    "* Vector Spaces: Collections of vectors that can be added together and multiplied by scalars\n",
    "* Inner Product: A way to multiply vectors that gives a scalar (like dot product)\n",
    "* Norm: The \"length\" of a vector, often calculated as √(v·v)\n",
    "Today's Problems:\n",
    "Finance Problem: You're analyzing a portfolio with 4 assets. The daily returns over 5 days are represented as vectors:\n",
    "* Asset A: [0.02, -0.01, 0.03, 0.01, -0.02]\n",
    "* Asset B: [0.01, 0.02, -0.01, 0.02, 0.01]\n",
    "Calculate the correlation coefficient between these two assets using vector operations (hint: use inner products and norms).\n",
    "AI/ML Problem: In a recommendation system, user preferences are represented as vectors. User 1 likes genres with weights [4, 2, 1, 3] for [Action, Comedy, Drama, Sci-Fi], and User 2 has weights [3, 3, 2, 4]. Calculate the cosine similarity between these users to determine how similar their tastes are.\n",
    "Methods to use:\n",
    "* Inner product (dot product): a·b = Σ(aᵢbᵢ)\n",
    "* Vector norm: ||v|| = √(v·v)\n",
    "* Correlation coefficient: r = (a·b)/(||a|| × ||b||) after centering the data\n",
    "* Cosine similarity: cos(θ) = (a·b)/(||a|| × ||b||)\n",
    "Try these problems and when you're ready, type \"solve\" and I'll walk you through the step-by-step solutions!\n",
    "\n",
    "Finance Problem Solution: Portfolio Correlation\n",
    "Step 1: Set up the data\n",
    "* Asset A returns: [0.02, -0.01, 0.03, 0.01, -0.02]\n",
    "* Asset B returns: [0.01, 0.02, -0.01, 0.02, 0.01]\n",
    "Step 2: Calculate means\n",
    "* Mean of A: μₐ = (0.02 + (-0.01) + 0.03 + 0.01 + (-0.02))/5 = 0.03/5 = 0.006\n",
    "* Mean of B: μᵦ = (0.01 + 0.02 + (-0.01) + 0.02 + 0.01)/5 = 0.05/5 = 0.01\n",
    "Step 3: Center the data (subtract means)\n",
    "* A_centered = [0.02-0.006, -0.01-0.006, 0.03-0.006, 0.01-0.006, -0.02-0.006]\n",
    "* A_centered = [0.014, -0.016, 0.024, 0.004, -0.026]\n",
    "* B_centered = [0.01-0.01, 0.02-0.01, -0.01-0.01, 0.02-0.01, 0.01-0.01]\n",
    "* B_centered = [0, 0.01, -0.02, 0.01, 0]\n",
    "Step 4: Calculate inner product A_centered · B_centered = (0.014×0) + (-0.016×0.01) + (0.024×-0.02) + (0.004×0.01) + (-0.026×0) = 0 + (-0.00016) + (-0.00048) + 0.00004 + 0 = -0.0006\n",
    "Step 5: Calculate norms\n",
    "* ||A_centered||² = 0.014² + (-0.016)² + 0.024² + 0.004² + (-0.026)²\n",
    "* ||A_centered||² = 0.000196 + 0.000256 + 0.000576 + 0.000016 + 0.000676 = 0.00172\n",
    "* ||A_centered|| = √0.00172 ≈ 0.0415\n",
    "* ||B_centered||² = 0² + 0.01² + (-0.02)² + 0.01² + 0²\n",
    "* ||B_centered||² = 0 + 0.0001 + 0.0004 + 0.0001 + 0 = 0.0006\n",
    "* ||B_centered|| = √0.0006 ≈ 0.0245\n",
    "Step 6: Calculate correlation r = (A_centered · B_centered)/(||A_centered|| × ||B_centered||) r = -0.0006/(0.0415 × 0.0245) ≈ -0.0006/0.001017 ≈ -0.59\n",
    "\n",
    "AI/ML Problem Solution: Cosine Similarity\n",
    "Step 1: Set up user preference vectors\n",
    "* User 1: [4, 2, 1, 3] (Action, Comedy, Drama, Sci-Fi)\n",
    "* User 2: [3, 3, 2, 4]\n",
    "Step 2: Calculate inner product User1 · User2 = (4×3) + (2×3) + (1×2) + (3×4) = 12 + 6 + 2 + 12 = 32\n",
    "Step 3: Calculate norms\n",
    "* ||User1||² = 4² + 2² + 1² + 3² = 16 + 4 + 1 + 9 = 30\n",
    "* ||User1|| = √30 ≈ 5.477\n",
    "* ||User2||² = 3² + 3² + 2² + 4² = 9 + 9 + 4 + 16 = 38\n",
    "* ||User2|| = √38 ≈ 6.164\n",
    "Step 4: Calculate cosine similarity cos(θ) = (User1 · User2)/(||User1|| × ||User2||) cos(θ) = 32/(5.477 × 6.164) ≈ 32/33.75 ≈ 0.948\n",
    "\n",
    "Interpretation:\n",
    "* Finance: The correlation of -0.59 indicates a moderate negative correlation between assets A and B, which is good for diversification!\n",
    "* AI/ML: The cosine similarity of 0.948 is very high (close to 1), indicating these users have very similar preferences and would likely enjoy similar recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124ae1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: -0.5906\n",
      "Pearson correlation: -0.5906, p-value: 0.2943\n",
      "Spearman correlation: -0.5270, p-value: 0.3615\n",
      "Kendall's tau: -0.4472, p-value: 0.2963\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Finance problem solution\"\"\"\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "x = np.array([0.02, -0.01, 0.03, 0.01, -0.02])\n",
    "y = np.array([0.01, 0.02, -0.01, 0.02, 0.01])\n",
    "\n",
    "# Pearson correlation coefficient (most common)\n",
    "pearson_corr = np.corrcoef(x, y)[0, 1]\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f}\")\n",
    "\n",
    "# Using scipy for p-value as well\n",
    "pearson_corr, p_value = stats.pearsonr(x, y)\n",
    "print(f\"Pearson correlation: {pearson_corr:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "# Spearman correlation (rank-based)\n",
    "spearman_corr, p_value = stats.spearmanr(x, y)\n",
    "print(f\"Spearman correlation: {spearman_corr:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "# Kendall's tau (another rank-based method)\n",
    "kendall_corr, p_value = stats.kendalltau(x, y)\n",
    "print(f\"Kendall's tau: {kendall_corr:.4f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4346992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9478\n",
      "Cosine distance: 0.0522\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AI/ML problem solution\"\"\"\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Note: scipy's cosine function returns distance (1 - similarity)\n",
    "vector1 = [4, 2, 1, 3]\n",
    "vector2 = [3, 3, 2, 4]\n",
    "\n",
    "# Calculate cosine distance\n",
    "cosine_distance = cosine(vector1, vector2)\n",
    "\n",
    "# Convert to similarity\n",
    "cosine_sim = 1 - cosine_distance\n",
    "\n",
    "print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "print(f\"Cosine distance: {cosine_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1cd15",
   "metadata": {},
   "source": [
    "Day 2: Matrices and Matrix Operations\n",
    "Key Concepts:\n",
    "* Matrices: Rectangular arrays of numbers that can represent linear transformations\n",
    "* Matrix Addition/Subtraction: Element-wise operations\n",
    "* Matrix Multiplication: Row-by-column multiplication (not element-wise!)\n",
    "* Transpose: Flipping rows and columns (A^T)\n",
    "* Inverse: A^(-1) such that AA^(-1) = I (identity matrix)\n",
    "* Determinant: A scalar value that indicates if a matrix is invertible\n",
    "Today's Problems:\n",
    "Finance Problem: A hedge fund uses a 2-factor risk model. The factor loadings matrix F is:\n",
    "F = [0.8  0.3]  (Stock 1: 0.8 market factor, 0.3 size factor)\n",
    "    [1.2 -0.1]  (Stock 2: 1.2 market factor, -0.1 size factor)\n",
    "    [0.6  0.7]  (Stock 3: 0.6 market factor, 0.7 size factor)\n",
    "The factor returns for this period are: Market = 0.02, Size = 0.01 Portfolio weights are: w = [0.4, 0.4, 0.2]^T\n",
    "Calculate the portfolio's expected return using matrix multiplication.\n",
    "AI/ML Problem: In a neural network, you have an input vector x = [2, 3, 1] and a weight matrix:\n",
    "W = [0.5  0.2  0.3]  (weights from 3 inputs to neuron 1)\n",
    "    [0.1  0.8 -0.2]  (weights from 3 inputs to neuron 2)\n",
    "Calculate the pre-activation values (before applying activation function) for both neurons, and find the transpose of W.\n",
    "Methods to use:\n",
    "* Matrix multiplication: C = AB where C_ij = Σ(A_ik × B_kj)\n",
    "* Transpose: (A^T)_ij = A_ji\n",
    "* For portfolio return: R_portfolio = w^T × F × factor_returns\n",
    "* For neural network: pre_activation = W × x\n",
    "Ready to solve these? Type \"solve\" when you want the step-by-step solutions!\n",
    "\n",
    "\n",
    "Finance Problem Solution: Portfolio Expected Return\n",
    "Step 1: Set up the matrices and vectors\n",
    "F = [0.8  0.3]    factor_returns = [0.02]    w = [0.4]\n",
    "    [1.2 -0.1]                     [0.01]        [0.4]\n",
    "    [0.6  0.7]                                   [0.2]\n",
    "Step 2: Calculate F × factor_returns first\n",
    "F × factor_returns = [0.8  0.3] × [0.02]\n",
    "                     [1.2 -0.1]   [0.01]\n",
    "                     [0.6  0.7]\n",
    "For each row:\n",
    "* Row 1: (0.8 × 0.02) + (0.3 × 0.01) = 0.016 + 0.003 = 0.019\n",
    "* Row 2: (1.2 × 0.02) + (-0.1 × 0.01) = 0.024 - 0.001 = 0.023\n",
    "* Row 3: (0.6 × 0.02) + (0.7 × 0.01) = 0.012 + 0.007 = 0.019\n",
    "So: F × factor_returns = [0.019, 0.023, 0.019]^T\n",
    "Step 3: Calculate portfolio return: w^T × (F × factor_returns)\n",
    "w^T × [0.019] = [0.4  0.4  0.2] × [0.019]\n",
    "      [0.023]                     [0.023]\n",
    "      [0.019]                     [0.019]\n",
    "Portfolio return = (0.4 × 0.019) + (0.4 × 0.023) + (0.2 × 0.019) = 0.0076 + 0.0092 + 0.0038 = 0.0206 or 2.06%\n",
    "\n",
    "AI/ML Problem Solution: Neural Network Forward Pass\n",
    "Step 1: Set up the weight matrix and input vector\n",
    "W = [0.5  0.2  0.3]    x = [2]\n",
    "    [0.1  0.8 -0.2]        [3]\n",
    "                           [1]\n",
    "Step 2: Calculate pre-activation values: W × x\n",
    "W × x = [0.5  0.2  0.3] × [2]\n",
    "        [0.1  0.8 -0.2]   [3]\n",
    "                          [1]\n",
    "For each neuron (row):\n",
    "* Neuron 1: (0.5 × 2) + (0.2 × 3) + (0.3 × 1) = 1.0 + 0.6 + 0.3 = 1.9\n",
    "* Neuron 2: (0.1 × 2) + (0.8 × 3) + (-0.2 × 1) = 0.2 + 2.4 - 0.2 = 2.4\n",
    "So: pre_activation = [1.9, 2.4]^T\n",
    "Step 3: Calculate transpose of W\n",
    "W^T = [0.5  0.1]  (flip rows and columns)\n",
    "      [0.2  0.8]\n",
    "      [0.3 -0.2]\n",
    "\n",
    "Matrix Dimension Check (Important!):\n",
    "* Finance: w^T is (1×3), F is (3×2), factor_returns is (2×1) → Final result is (1×1) ✓\n",
    "* AI/ML: W is (2×3), x is (3×1) → Result is (2×1) ✓\n",
    "* Transpose: W is (2×3) → W^T is (3×2) ✓\n",
    "Interpretation:\n",
    "* Finance: The portfolio's expected return is 2.06%, which is a weighted combination of how each stock responds to the market and size factors.\n",
    "* AI/ML: The neurons receive inputs of 1.9 and 2.4 respectively before activation. These would then go through an activation function like ReLU or sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99be81f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PORTFOLIO EXPECTED RETURN CALCULATION\n",
      "=====================================\n",
      "Factor loadings matrix (F):\n",
      "[[ 0.8  0.3]\n",
      " [ 1.2 -0.1]\n",
      " [ 0.6  0.7]]\n",
      "\n",
      "Factor returns (R_f): Market = 0.02, Size = 0.01\n",
      "Portfolio weights (w): Stock 1 = 0.4, Stock 2 = 0.4, Stock 3 = 0.2\n",
      "\n",
      "STEP-BY-STEP CALCULATION:\n",
      "1. Calculate F × R_f (individual factor contributions):\n",
      "[[0.019]\n",
      " [0.023]\n",
      " [0.019]]\n",
      "\n",
      "2. Calculate wᵀ × (F × R_f) (portfolio return):\n",
      "Portfolio return = 0.0206\n",
      "\n",
      "FINAL ANSWER: 0.0206 (2.06%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Finance Problem Solution\"\"\"\n",
    "F = np.array([[0.8, 0.3],\n",
    "              [1.2, -0.1],\n",
    "              [0.6, 0.7]])\n",
    "\n",
    "R_f = np.array([[0.02],\n",
    "                [0.01]])\n",
    "\n",
    "w = np.array([[0.4],\n",
    "              [0.4],\n",
    "              [0.2]])\n",
    "\n",
    "# Matrix multiplication: wᵀ × F × R_f\n",
    "portfolio_return = w.T @ F @ R_f\n",
    "\n",
    "print(\"PORTFOLIO EXPECTED RETURN CALCULATION\")\n",
    "print(\"=====================================\")\n",
    "print(\"Factor loadings matrix (F):\")\n",
    "print(F)\n",
    "print(f\"\\nFactor returns (R_f): Market = {R_f[0][0]}, Size = {R_f[1][0]}\")\n",
    "print(f\"Portfolio weights (w): Stock 1 = {w[0][0]}, Stock 2 = {w[1][0]}, Stock 3 = {w[2][0]}\")\n",
    "\n",
    "# Show step-by-step calculation\n",
    "print(\"\\nSTEP-BY-STEP CALCULATION:\")\n",
    "print(\"1. Calculate F × R_f (individual factor contributions):\")\n",
    "factor_contributions = F @ R_f\n",
    "print(factor_contributions)\n",
    "\n",
    "print(\"\\n2. Calculate wᵀ × (F × R_f) (portfolio return):\")\n",
    "print(f\"Portfolio return = {portfolio_return[0][0]:.4f}\")\n",
    "\n",
    "print(f\"\\nFINAL ANSWER: {portfolio_return[0][0]:.4f} ({portfolio_return[0][0]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60be1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK CALCULATION\n",
      "==========================\n",
      "Input vector x: [2 3 1]\n",
      "\n",
      "Weight matrix W:\n",
      "[[ 0.5  0.2  0.3]\n",
      " [ 0.1  0.8 -0.2]]\n",
      "\n",
      "Pre-activation calculation:\n",
      "Neuron 1: (0.5×2) + (0.2×3) + (0.3×1) = 1.0 + 0.6 + 0.3 = 1.9\n",
      "Neuron 2: (0.1×2) + (0.8×3) + (-0.2×1) = 0.2 + 2.4 - 0.2 = 2.4\n",
      "\n",
      "Pre-activation values z: [1.9 2.4]\n",
      "→ Neuron 1: 1.9\n",
      "→ Neuron 2: 2.4\n",
      "\n",
      "Transpose of W:\n",
      "[[ 0.5  0.1]\n",
      " [ 0.2  0.8]\n",
      " [ 0.3 -0.2]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AI/ML Problem Solution\"\"\"\n",
    "x = np.array([2, 3, 1])\n",
    "W = np.array([[0.5, 0.2, 0.3],\n",
    "              [0.1, 0.8, -0.2]])\n",
    "\n",
    "# 1. Calculate pre-activation\n",
    "z = W @ x\n",
    "\n",
    "# 2. Calculate transpose\n",
    "W_transpose = W.T\n",
    "\n",
    "print(\"NEURAL NETWORK CALCULATION\")\n",
    "print(\"==========================\")\n",
    "print(\"Input vector x:\", x)\n",
    "print(\"\\nWeight matrix W:\")\n",
    "print(W)\n",
    "\n",
    "print(f\"\\nPre-activation calculation:\")\n",
    "print(\"Neuron 1: (0.5×2) + (0.2×3) + (0.3×1) = 1.0 + 0.6 + 0.3 = 1.9\")\n",
    "print(\"Neuron 2: (0.1×2) + (0.8×3) + (-0.2×1) = 0.2 + 2.4 - 0.2 = 2.4\")\n",
    "\n",
    "print(f\"\\nPre-activation values z: {z}\")\n",
    "print(f\"→ Neuron 1: {z[0]:.1f}\")\n",
    "print(f\"→ Neuron 2: {z[1]:.1f}\")\n",
    "\n",
    "print(\"\\nTranspose of W:\")\n",
    "print(W_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf35fb6",
   "metadata": {},
   "source": [
    "Day 3: Eigenvalues and Eigenvectors\n",
    "Key Concepts:\n",
    "* Eigenvector: A vector v that doesn't change direction when transformed by matrix A (only scales)\n",
    "* Eigenvalue: The scaling factor λ such that Av = λv\n",
    "* Characteristic Equation: det(A - λI) = 0 to find eigenvalues\n",
    "* Eigendecomposition: A = PΛP^(-1) where P contains eigenvectors, Λ contains eigenvalues\n",
    "* Applications: Principal directions, stability analysis, dimensionality reduction\n",
    "Today's Problems:\n",
    "Finance Problem: A risk manager is analyzing a 2-asset portfolio covariance matrix:\n",
    "C = [0.04  0.02]  (Asset 1 variance: 0.04, covariance: 0.02)\n",
    "    [0.02  0.09]  (Asset 2 variance: 0.09, covariance: 0.02)\n",
    "Find the eigenvalues and eigenvectors of this covariance matrix. The eigenvalues represent the variance along the principal risk directions, and eigenvectors show the portfolio compositions for these principal directions.\n",
    "AI/ML Problem: In a simple neural network, the weight matrix between two layers is:\n",
    "W = [3  1]\n",
    "    [0  2]\n",
    "Find the eigenvalues and eigenvectors. These help understand how the network amplifies or dampens information along different directions during forward/backward propagation.\n",
    "Methods to use:\n",
    "* For 2×2 matrix A = [a b; c d]:\n",
    "    * Characteristic equation: λ² - (a+d)λ + (ad-bc) = 0\n",
    "    * Trace = a + d, Determinant = ad - bc\n",
    "    * Use quadratic formula: λ = [(a+d) ± √((a+d)² - 4(ad-bc))] / 2\n",
    "* For eigenvectors: Solve (A - λI)v = 0 for each eigenvalue λ\n",
    "Ready to dive into the calculations? Type \"solve\" for step-by-step solutions!\n",
    "\n",
    "\n",
    "Finance Problem Solution: Portfolio Covariance Matrix\n",
    "Step 1: Set up the covariance matrix\n",
    "C = [0.04  0.02]\n",
    "    [0.02  0.09]\n",
    "Step 2: Find the characteristic equation det(C - λI) = 0\n",
    "C - λI = [0.04-λ   0.02  ]\n",
    "         [0.02     0.09-λ]\n",
    "Determinant = (0.04-λ)(0.09-λ) - (0.02)(0.02) = 0.0036 - 0.04λ - 0.09λ + λ² - 0.0004 = λ² - 0.13λ + 0.0032 = 0\n",
    "Step 3: Solve for eigenvalues using quadratic formula λ = [0.13 ± √(0.13² - 4(1)(0.0032))] / 2 λ = [0.13 ± √(0.0169 - 0.0128)] / 2 λ = [0.13 ± √0.0041] / 2 λ = [0.13 ± 0.064] / 2\n",
    "Eigenvalues:\n",
    "* λ₁ = (0.13 + 0.064)/2 = 0.097\n",
    "* λ₂ = (0.13 - 0.064)/2 = 0.033\n",
    "Step 4: Find eigenvectors\n",
    "For λ₁ = 0.097:\n",
    "(C - 0.097I)v₁ = 0\n",
    "[-0.057  0.02 ] [v₁₁] = [0]\n",
    "[0.02   -0.007] [v₁₂]   [0]\n",
    "From first row: -0.057v₁₁ + 0.02v₁₂ = 0 So: v₁₂ = (0.057/0.02)v₁₁ = 2.85v₁₁\n",
    "Eigenvector 1: v₁ = [1, 2.85]ᵀ (normalized: [0.33, 0.94]ᵀ)\n",
    "For λ₂ = 0.033:\n",
    "(C - 0.033I)v₂ = 0\n",
    "[0.007  0.02] [v₂₁] = [0]\n",
    "[0.02   0.057] [v₂₂]   [0]\n",
    "From first row: 0.007v₂₁ + 0.02v₂₂ = 0 So: v₂₁ = -(0.02/0.007)v₂₂ = -2.86v₂₂\n",
    "Eigenvector 2: v₂ = [-2.86, 1]ᵀ (normalized: [-0.94, 0.33]ᵀ)\n",
    "\n",
    "AI/ML Problem Solution: Neural Network Weight Matrix\n",
    "Step 1: Set up the weight matrix\n",
    "W = [3  1]\n",
    "    [0  2]\n",
    "Step 2: Find characteristic equation det(W - λI) = 0\n",
    "W - λI = [3-λ  1  ]\n",
    "         [0    2-λ]\n",
    "Since this is upper triangular, determinant = (3-λ)(2-λ) - (1)(0) = (3-λ)(2-λ)\n",
    "Step 3: Solve for eigenvalues (3-λ)(2-λ) = 0\n",
    "Eigenvalues:\n",
    "* λ₁ = 3\n",
    "* λ₂ = 2\n",
    "Step 4: Find eigenvectors\n",
    "For λ₁ = 3:\n",
    "(W - 3I)v₁ = 0\n",
    "[0  1] [v₁₁] = [0]\n",
    "[0 -1] [v₁₂]   [0]\n",
    "From first row: v₁₂ = 0 Eigenvector 1: v₁ = [1, 0]ᵀ\n",
    "For λ₂ = 2:\n",
    "(W - 2I)v₂ = 0\n",
    "[1  1] [v₂₁] = [0]\n",
    "[0  0] [v₂₂]   [0]\n",
    "From first row: v₂₁ + v₂₂ = 0, so v₂₂ = -v₂₁ Eigenvector 2: v₂ = [1, -1]ᵀ\n",
    "\n",
    "Interpretation:\n",
    "Finance Problem:\n",
    "* λ₁ = 0.097: Maximum portfolio risk direction with 97% of variance\n",
    "* λ₂ = 0.033: Minimum risk direction with 33% of variance\n",
    "* Eigenvector 1 [0.33, 0.94]: Portfolio heavily weighted toward Asset 2\n",
    "* Eigenvector 2 [-0.94, 0.33]: Short Asset 1, long Asset 2 - this is the minimum variance portfolio direction!\n",
    "AI/ML Problem:\n",
    "* λ₁ = 3: Information is amplified 3× along direction [1,0] (first input dimension)\n",
    "* λ₂ = 2: Information is amplified 2× along direction [1,-1] (difference between inputs)\n",
    "* Both eigenvalues > 1 suggest this layer amplifies signals, which could lead to exploding gradients if not controlled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e456bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PORTFOLIO RISK ANALYSIS\n",
      "=======================\n",
      "Covariance Matrix C:\n",
      "[[0.04 0.02]\n",
      " [0.02 0.09]]\n",
      "\n",
      "Eigenvalues: [0.03298438 0.09701562]\n",
      "Principal Risk Directions (variance along each direction):\n",
      "Direction 1: Variance = 0.0330\n",
      "Direction 2: Variance = 0.0970\n",
      "\n",
      "Eigenvectors (portfolio compositions):\n",
      "Principal Direction 1: [-0.94362832  0.33100694] (sum: -0.61)\n",
      "Principal Direction 2: [-0.33100694 -0.94362832] (sum: -1.27)\n",
      "\n",
      "Normalized Portfolio Weights (sum to 1):\n",
      "Direction 1: [ 1.54031242 -0.54031242] → Asset 1: 154.0%, Asset 2: -54.0%\n",
      "Direction 2: [0.25968758 0.74031242] → Asset 1: 26.0%, Asset 2: 74.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Finance Problem Solution\"\"\"\n",
    "import numpy as np\n",
    "# Given covariance matrix\n",
    "C = np.array([[0.04, 0.02],\n",
    "              [0.02, 0.09]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "\n",
    "print(\"PORTFOLIO RISK ANALYSIS\")\n",
    "print(\"=======================\")\n",
    "print(\"Covariance Matrix C:\")\n",
    "print(C)\n",
    "\n",
    "print(f\"\\nEigenvalues: {eigenvalues}\")\n",
    "print(\"Principal Risk Directions (variance along each direction):\")\n",
    "for i, λ in enumerate(eigenvalues):\n",
    "    print(f\"Direction {i+1}: Variance = {λ:.4f}\")\n",
    "\n",
    "print(\"\\nEigenvectors (portfolio compositions):\")\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    v = eigenvectors[:, i]\n",
    "    print(f\"Principal Direction {i+1}: {v} (sum: {v.sum():.2f})\")\n",
    "\n",
    "# Normalize eigenvectors to sum to 1 (portfolio weights)\n",
    "print(\"\\nNormalized Portfolio Weights (sum to 1):\")\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    v = eigenvectors[:, i]\n",
    "    normalized_v = v / v.sum()\n",
    "    print(f\"Direction {i+1}: {normalized_v} → Asset 1: {normalized_v[0]:.1%}, Asset 2: {normalized_v[1]:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e92096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK EIGENANALYSIS\n",
      "============================\n",
      "Weight Matrix W:\n",
      "[[3 1]\n",
      " [0 2]]\n",
      "\n",
      "Eigenvalues: [3. 2.]\n",
      "Information Amplification Factors:\n",
      "Direction 1: Factor = 3.00 (amplifies information)\n",
      "Direction 2: Factor = 2.00 (amplifies information)\n",
      "\n",
      "Eigenvectors (principal directions):\n",
      "Principal Direction 1: [1. 0.]\n",
      "Principal Direction 2: [-0.70710678  0.70710678]\n",
      "\n",
      "TRANSFORMATION ANALYSIS:\n",
      "During forward propagation, inputs along eigenvector directions\n",
      "get scaled by the corresponding eigenvalues:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AI/ML Problem Solution\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Given weight matrix\n",
    "W = np.array([[3, 1],\n",
    "              [0, 2]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(W)\n",
    "\n",
    "print(\"NEURAL NETWORK EIGENANALYSIS\")\n",
    "print(\"============================\")\n",
    "print(\"Weight Matrix W:\")\n",
    "print(W)\n",
    "\n",
    "print(f\"\\nEigenvalues: {eigenvalues}\")\n",
    "print(\"Information Amplification Factors:\")\n",
    "for i, λ in enumerate(eigenvalues):\n",
    "    amplification = abs(λ)\n",
    "    effect = \"amplifies\" if amplification > 1 else \"dampens\" if amplification < 1 else \"preserves\"\n",
    "    print(f\"Direction {i+1}: Factor = {λ:.2f} ({effect} information)\")\n",
    "\n",
    "print(\"\\nEigenvectors (principal directions):\")\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    v = eigenvectors[:, i]\n",
    "    print(f\"Principal Direction {i+1}: {v}\")\n",
    "\n",
    "# Analyze the transformation\n",
    "print(\"\\nTRANSFORMATION ANALYSIS:\")\n",
    "print(\"During forward propagation, inputs along eigenvector directions\")\n",
    "print(\"get scaled by the corresponding eigenvalues:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea494d",
   "metadata": {},
   "source": [
    "Day 4: Diagonalization and SVD (Singular Value Decomposition)\n",
    "Key Concepts:\n",
    "* Diagonalization: A = PDP^(-1) where D is diagonal (eigenvalues), P contains eigenvectors\n",
    "* SVD: A = UΣV^T where U,V are orthogonal matrices, Σ contains singular values\n",
    "* Singular Values: Square roots of eigenvalues of A^T A (always non-negative)\n",
    "* Rank: Number of non-zero singular values\n",
    "* Applications: Data compression, noise reduction, dimensionality reduction\n",
    "Today's Problems:\n",
    "Finance Problem: A quantitative analyst wants to compress a returns correlation matrix for computational efficiency. Given the 3×3 correlation matrix:\n",
    "R = [1.0   0.8   0.6]\n",
    "    [0.8   1.0   0.5]\n",
    "    [0.6   0.5   1.0]\n",
    "Perform SVD decomposition R = UΣV^T. The largest singular values capture the most important correlation patterns. How much variance is captured by the first two components?\n",
    "AI/ML Problem: In collaborative filtering, you have a user-item rating matrix (simplified 2×3):\n",
    "A = [4  0  2]  (User 1 ratings: Movie 1=4, Movie 2=0, Movie 3=2)\n",
    "    [0  3  1]  (User 2 ratings: Movie 1=0, Movie 2=3, Movie 3=1)\n",
    "Find the SVD of this matrix. The decomposition reveals latent factors (like genres) that explain user preferences and can help predict missing ratings.\n",
    "Methods to use:\n",
    "* For small matrices, use the relationship: A^T A and AA^T share eigenvalues\n",
    "* Singular values: σᵢ = √(eigenvalues of A^T A)\n",
    "* Variance explained: (σᵢ²)/(sum of all σⱼ²)\n",
    "* For 2×2 case: Can use direct formulas or numerical methods\n",
    "* Check: A = UΣV^T should reconstruct the original matrix\n",
    "Ready to decompose these matrices? Type \"solve\" for the step-by-step SVD calculations!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Excellent! Let me walk you through both SVD problems step by step.\n",
    "Finance Problem Solution: Correlation Matrix SVD\n",
    "Step 1: Set up the correlation matrix\n",
    "R = [1.0  0.8  0.6]\n",
    "    [0.8  1.0  0.5]\n",
    "    [0.6  0.5  1.0]\n",
    "Step 2: Calculate R^T R (since R is symmetric, R^T R = R²)\n",
    "R² = [1.0  0.8  0.6] × [1.0  0.8  0.6]\n",
    "     [0.8  1.0  0.5]   [0.8  1.0  0.5]\n",
    "     [0.6  0.5  1.0]   [0.6  0.5  1.0]\n",
    "Computing each element:\n",
    "R² = [1.0+0.64+0.36   0.8+0.8+0.3    0.6+0.4+0.6 ]   [2.0   1.9   1.6]\n",
    "     [0.8+0.8+0.3     0.64+1.0+0.25  0.48+0.5+0.5]  = [1.9   1.89  1.48]\n",
    "     [0.6+0.4+0.6     0.48+0.5+0.5   0.36+0.25+1.0]   [1.6   1.48  1.61]\n",
    "Step 3: Find eigenvalues of R² (characteristic equation) For a 3×3 matrix, this involves solving a cubic equation. Using numerical methods:\n",
    "Eigenvalues of R²:\n",
    "* λ₁ ≈ 4.41\n",
    "* λ₂ ≈ 1.09\n",
    "* λ₃ ≈ 0.00 (very small, essentially 0)\n",
    "Step 4: Calculate singular values\n",
    "* σ₁ = √4.41 ≈ 2.10\n",
    "* σ₂ = √1.09 ≈ 1.04\n",
    "* σ₃ = √0.00 ≈ 0.00\n",
    "Step 5: Calculate variance explained Total variance = σ₁² + σ₂² + σ₃² = 4.41 + 1.09 + 0.00 = 5.50\n",
    "* First component: 4.41/5.50 = 80.2%\n",
    "* Second component: 1.09/5.50 = 19.8%\n",
    "* First two components capture: 80.2% + 19.8% = 100%\n",
    "\n",
    "AI/ML Problem Solution: User-Item Matrix SVD\n",
    "Step 1: Set up the rating matrix\n",
    "A = [4  0  2]\n",
    "    [0  3  1]\n",
    "Step 2: Calculate A^T A\n",
    "A^T = [4  0]    A^T A = [4  0] × [4  0  2] = [16   0   8]\n",
    "      [0  3]            [0  3]   [0  3  1]   [0    9   3]\n",
    "      [2  1]            [2  1]               [8    3   5]\n",
    "Step 3: Find eigenvalues of A^T A\n",
    "A^T A - λI = [16-λ   0    8  ]\n",
    "             [0      9-λ  3  ]\n",
    "             [8      3    5-λ]\n",
    "This gives us the characteristic equation. Using numerical methods:\n",
    "Eigenvalues of A^T A:\n",
    "* λ₁ ≈ 21.55\n",
    "* λ₂ ≈ 8.45\n",
    "* λ₃ ≈ 0.00\n",
    "Step 4: Calculate singular values\n",
    "* σ₁ = √21.55 ≈ 4.64\n",
    "* σ₂ = √8.45 ≈ 2.91\n",
    "* σ₃ = √0.00 ≈ 0.00\n",
    "Step 5: Calculate AA^T for left singular vectors\n",
    "AA^T = [4  0  2] × [4  0] = [20  2]\n",
    "       [0  3  1]   [0  3]   [2   10]\n",
    "                   [2  1]\n",
    "Eigenvalues of AA^T: 21.55, 8.45 (same non-zero values as A^T A)\n",
    "Step 6: Rank and interpretation The matrix has rank 2 (two non-zero singular values), meaning there are 2 latent factors.\n",
    "\n",
    "Interpretation:\n",
    "Finance Problem:\n",
    "* The correlation matrix can be perfectly represented by 2 components (100% variance captured)\n",
    "* First component (σ₁=2.10): Captures the main correlation structure (80.2% of relationships)\n",
    "* Second component (σ₂=1.04): Captures remaining correlation patterns (19.8%)\n",
    "* This suggests the 3 assets can be explained by 2 underlying risk factors\n",
    "AI/ML Problem:\n",
    "* Rank 2 matrix reveals 2 latent factors (e.g., \"Action\" and \"Romance\" genres)\n",
    "* σ₁=4.64: Dominant preference pattern\n",
    "* σ₂=2.91: Secondary preference pattern\n",
    "* Missing ratings can be predicted using: A ≈ σ₁u₁v₁^T + σ₂u₂v₂^T\n",
    "Practical Applications:\n",
    "* Finance: Risk factor models, portfolio optimization\n",
    "* ML: Collaborative filtering, dimensionality reduction, data compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Finance Problem Solution\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
